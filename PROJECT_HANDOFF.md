# üìã AI-JARVIS - Complete Project Handoff Document

**Version:** 1.0.0  
**Date:** December 3, 2025  
**Status:** Production-Ready  
**Repository:** https://github.com/Youni-G5/AI-JARVIS

---

## üìä Executive Summary

### What is AI-JARVIS?

**AI-JARVIS** is a **production-grade autonomous AI assistant** inspired by the JARVIS system from Iron Man. It's a complete, local-first platform that combines:

- üé§ **Voice recognition** (Speech-to-Text with Whisper)
- üß† **AI reasoning** (Local LLM with Ollama/Llama)
- üó£Ô∏è **Voice synthesis** (Text-to-Speech with Piper)
- üëÅÔ∏è **Computer vision** (Object detection with YOLOv8, OCR with Tesseract)
- ‚ö° **System automation** (Secure action execution with sandboxing)
- üè† **IoT control** (MQTT home automation)
- üß† **Contextual memory** (Vector storage with ChromaDB)
- üé® **Modern UI** (Real-time dashboard with Next.js)

### Key Characteristics

‚úÖ **Production-Ready** - Not a prototype, enterprise-grade architecture  
‚úÖ **Local-First** - No cloud dependency, complete privacy  
‚úÖ **Microservices** - 7 independent services, horizontally scalable  
‚úÖ **Secure** - Multi-layer security, sandboxed execution, audit logging  
‚úÖ **Documented** - 15+ documentation files, 10,000+ words  
‚úÖ **Tested** - CI/CD pipeline, automated testing, code quality checks  

---

## üéØ Project Goals & Vision

### Primary Goal
Create a **fully autonomous AI assistant** that can:
1. Listen and understand voice commands
2. See and analyze visual input
3. Reason about complex tasks
4. Execute actions securely
5. Remember context and learn
6. Control IoT devices and systems

### Vision (Long-term)
- Replace traditional personal assistants (Siri, Alexa, Google Assistant)
- Provide 100% privacy (local processing)
- Enable advanced automation (multi-step tasks)
- Open-source community-driven development
- Plugin ecosystem for extensibility

### Target Audience
- Developers building AI assistants
- Privacy-conscious users
- Home automation enthusiasts
- Researchers in AI/ML
- Companies needing local AI solutions

---

## üèóÔ∏è Technical Architecture

### System Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FRONTEND (Next.js + React)                 ‚îÇ
‚îÇ              - Dashboard UI                                   ‚îÇ
‚îÇ              - Real-time WebSocket                            ‚îÇ
‚îÇ              - Voice/Vision controls                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ HTTP REST + WebSocket
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               ORCHESTRATOR CORE (FastAPI)                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Request ‚Üí Plan ‚Üí Validate ‚Üí Execute ‚Üí Respond        ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  Components:                                                  ‚îÇ
‚îÇ  ‚Ä¢ Planning Engine (LLM-based action planning)               ‚îÇ
‚îÇ  ‚Ä¢ Safety Validator (multi-layer security checks)            ‚îÇ
‚îÇ  ‚Ä¢ Action Executor (orchestrates service calls)              ‚îÇ
‚îÇ  ‚Ä¢ Memory Manager (context retrieval/storage)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ
    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ                   ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê ‚îÇ ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îê ‚îÇ ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îê ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STT  ‚îÇ ‚îÇ ‚îÇTTS ‚îÇ ‚îÇ ‚îÇLLM ‚îÇ ‚îÇ ‚îÇ Vision ‚îÇ  ‚îÇ  Memory   ‚îÇ
‚îÇService‚îÇ ‚îÇServ.‚îÇ ‚îÇAgent‚îÇ ‚îÇ Service‚îÇ  ‚îÇ ChromaDB  ‚îÇ
‚îÇ      ‚îÇ ‚îÇ     ‚îÇ ‚îÇ     ‚îÇ ‚îÇ        ‚îÇ  ‚îÇ           ‚îÇ
‚îÇWhisper‚îÇ ‚îÇPiper‚îÇ ‚îÇOllama‚îÇ ‚îÇYOLOv8 ‚îÇ  ‚îÇ Vectors   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ OCR    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ        ‚îÇ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
      ‚îÇAction ‚îÇ   ‚îÇ
      ‚îÇExecutor‚îÇ  ‚îÇ
      ‚îÇ       ‚îÇ   ‚îÇ
      ‚îÇSandbox‚îÇ   ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
          ‚îÇ       ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ  OS   ‚îÇ   ‚îÇ   ‚îÇ Bridge API ‚îÇ
      ‚îÇActions‚îÇ   ‚îÇ   ‚îÇ  Gateway   ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇPostgreSQL   ‚îÇ
           ‚îÇRedis        ‚îÇ
           ‚îÇMQTT Broker  ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Microservices Breakdown

#### 1. **Orchestrator Core** (Port 8000)
**Role:** Central brain, coordinates all other services  
**Tech:** Python 3.11, FastAPI, asyncio  
**Responsibilities:**
- Receive user requests (voice, text, visual)
- Generate execution plans using LLM
- Validate actions for safety
- Orchestrate service calls
- Store/retrieve context from memory
- Return responses to frontend

**Key Files:**
- `apps/orchestrator_core/main.py` - FastAPI app entry point
- `apps/orchestrator_core/core/orchestrator.py` - Main orchestration logic
- `apps/orchestrator_core/core/planning.py` - LLM plan generation
- `apps/orchestrator_core/core/safety.py` - Security validation
- `apps/orchestrator_core/core/executor.py` - Action execution

---

#### 2. **STT Service** (Port 8001)
**Role:** Convert speech to text  
**Tech:** Whisper (OpenAI), PyTorch  
**Features:**
- Streaming audio input
- Batch file processing
- Multi-language support
- Real-time transcription

**API Endpoints:**
- `POST /transcribe` - Upload audio file
- `POST /stream` - Real-time streaming
- `GET /health` - Service health check

**Key Files:**
- `apps/stt_service/main.py` - Service implementation
- `apps/stt_service/Dockerfile` - Container definition

---

#### 3. **TTS Service** (Port 8002)
**Role:** Convert text to natural speech  
**Tech:** Piper TTS (offline neural TTS)  
**Features:**
- Multi-language voice synthesis
- Adjustable speed
- Multiple voice options
- High-quality output

**API Endpoints:**
- `POST /synthesize` - Generate speech from text
- `GET /voices` - List available voices
- `POST /test` - Test synthesis

**Key Files:**
- `apps/tts_service/main.py` - Service implementation

---

#### 4. **LLM Agent** (Port 8003)
**Role:** AI reasoning and decision making  
**Tech:** Ollama (llama.cpp wrapper)  
**Models:** Llama 3.2, Mistral, others  
**Features:**
- Local LLM inference
- Chat completion
- Action plan generation
- Context-aware responses

**API Endpoints:**
- `POST /generate` - Text completion
- `POST /chat` - Conversation
- `GET /models` - List models
- `POST /pull` - Download new model

**Key Files:**
- `apps/llm_agent/main.py` - Ollama API wrapper

---

#### 5. **Vision Service** (Port 8004)
**Role:** Computer vision and OCR  
**Tech:** YOLOv8 (Ultralytics), Tesseract OCR  
**Features:**
- Object detection
- Scene analysis
- Text extraction (OCR)
- Multi-language OCR

**API Endpoints:**
- `POST /detect` - Detect objects in image
- `POST /ocr` - Extract text from image
- `POST /analyze` - Combined detection + OCR

**Key Files:**
- `apps/vision_service/main.py` - Vision pipeline

---

#### 6. **Action Executor** (Port 8006)
**Role:** Secure system action execution  
**Tech:** Docker-in-Docker sandboxing  
**Features:**
- Sandboxed execution
- OS command execution
- IoT device control
- Audit logging
- Dry-run mode

**API Endpoints:**
- `POST /execute` - Execute action
- `POST /validate` - Validate without executing
- `GET /actions` - List available actions

**Security Features:**
- Blacklist dangerous commands
- Permission-based access control
- Resource limits
- Complete audit trail

**Key Files:**
- `apps/action_executor/main.py` - API
- `apps/action_executor/executor.py` - Execution logic

---

#### 7. **Bridge API** (Port 8007)
**Role:** Unified API gateway  
**Tech:** FastAPI reverse proxy  
**Features:**
- Single entry point for all services
- Request routing
- Health aggregation
- CORS handling

**Key Files:**
- `apps/bridge_api/main.py` - Gateway implementation

---

### Infrastructure Services

#### PostgreSQL (Port 5432)
- Persistent data storage
- User settings
- Action history

#### Redis (Port 6379)
- Caching layer
- Pub/Sub messaging
- Session storage

#### ChromaDB (Port 8005)
- Vector database
- Semantic memory
- Context retrieval

#### Ollama (Port 11434)
- LLM backend
- Model management
- Inference engine

#### Mosquitto MQTT (Port 1883)
- IoT message broker
- Device communication
- Event streaming

---

## üìÇ Project Structure

```
AI-JARVIS/
‚îú‚îÄ‚îÄ apps/                          # Microservices
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator_core/         # Main orchestrator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/                   # FastAPI routes
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ health.py          # Health checks
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ actions.py         # Action endpoints
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memory.py          # Memory endpoints
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ websocket.py       # WebSocket handler
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/                  # Business logic
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py    # Main orchestrator
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ planning.py        # Plan generation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ safety.py          # Security validation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ executor.py        # Action execution
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Configuration
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logger.py          # Logging setup
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/              # Service clients
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_client.py      # LLM communication
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memory_client.py   # Memory operations
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ action_client.py   # Action execution
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile             # Container definition
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py                # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ stt_service/               # Speech-to-Text
‚îÇ   ‚îú‚îÄ‚îÄ tts_service/               # Text-to-Speech
‚îÇ   ‚îú‚îÄ‚îÄ llm_agent/                 # LLM reasoning
‚îÇ   ‚îú‚îÄ‚îÄ vision_service/            # Computer vision
‚îÇ   ‚îú‚îÄ‚îÄ action_executor/           # Action execution
‚îÇ   ‚îî‚îÄ‚îÄ bridge_api/                # API gateway
‚îÇ
‚îú‚îÄ‚îÄ frontend/                      # Next.js dashboard
‚îÇ   ‚îú‚îÄ‚îÄ pages/                     # React pages
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ _app.tsx               # App wrapper
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.tsx              # Dashboard
‚îÇ   ‚îú‚îÄ‚îÄ styles/                    # CSS
‚îÇ   ‚îú‚îÄ‚îÄ package.json               # Node dependencies
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                 # Frontend container
‚îÇ   ‚îî‚îÄ‚îÄ next.config.js             # Next.js config
‚îÇ
‚îú‚îÄ‚îÄ docs/                          # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ Architecture.md            # System design
‚îÇ   ‚îú‚îÄ‚îÄ Installation.md            # Setup guide
‚îÇ   ‚îú‚îÄ‚îÄ Security.md                # Security policy
‚îÇ   ‚îú‚îÄ‚îÄ ROADMAP.md                 # Future plans
‚îÇ   ‚îú‚îÄ‚îÄ CODE_AUDIT.md              # Code quality report
‚îÇ   ‚îú‚îÄ‚îÄ VERIFICATION_CHECKLIST.md  # Testing guide
‚îÇ   ‚îî‚îÄ‚îÄ CI_CD.md                   # DevOps guide
‚îÇ
‚îú‚îÄ‚îÄ prompts/                       # AI prompts
‚îÇ   ‚îú‚îÄ‚îÄ system_orchestrator.txt    # Main system prompt
‚îÇ   ‚îî‚îÄ‚îÄ permissions.yml            # Action permissions
‚îÇ
‚îú‚îÄ‚îÄ infra/                         # Infrastructure configs
‚îÇ   ‚îú‚îÄ‚îÄ prometheus/                # Monitoring
‚îÇ   ‚îî‚îÄ‚îÄ mosquitto/                 # MQTT broker
‚îÇ
‚îú‚îÄ‚îÄ scripts/                       # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ setup.sh                   # Installation script
‚îÇ   ‚îî‚îÄ‚îÄ download_models.sh         # AI model downloader
‚îÇ
‚îú‚îÄ‚îÄ tests/                         # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ test_orchestrator.py       # Unit tests
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py                # Test fixtures
‚îÇ
‚îú‚îÄ‚îÄ .github/workflows/             # CI/CD
‚îÇ   ‚îú‚îÄ‚îÄ ci.yml                     # Continuous integration
‚îÇ   ‚îú‚îÄ‚îÄ cd.yml                     # Deployment
‚îÇ   ‚îî‚îÄ‚îÄ security.yml               # Security scans
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml             # Service orchestration
‚îú‚îÄ‚îÄ Makefile                       # Build automation
‚îú‚îÄ‚îÄ .env.example                   # Environment template
‚îú‚îÄ‚îÄ pyproject.toml                 # Python config
‚îú‚îÄ‚îÄ pytest.ini                     # Test configuration
‚îú‚îÄ‚îÄ README.md                      # Project overview
‚îú‚îÄ‚îÄ CHANGELOG.md                   # Version history
‚îú‚îÄ‚îÄ CONTRIBUTING.md                # Contribution guide
‚îú‚îÄ‚îÄ LICENSE                        # MIT License
‚îî‚îÄ‚îÄ PROJECT_HANDOFF.md             # This document
```

---

## üöÄ Quick Start Guide

### Prerequisites

**Required:**
- Docker Desktop 24.0+ (Windows/Mac) or Docker Engine (Linux)
- Docker Compose 2.0+
- 16GB RAM minimum (32GB recommended)
- 50GB free disk space

**Optional:**
- NVIDIA GPU with CUDA support (for faster inference)
- Python 3.11+ (for local development)
- Node.js 18+ (for frontend development)

### Installation Steps

#### 1. Clone Repository
```bash
git clone https://github.com/Youni-G5/AI-JARVIS.git
cd AI-JARVIS
```

#### 2. Configure Environment
```bash
# Copy environment template
cp .env.example .env

# Edit configuration (use your preferred editor)
nano .env

# Key variables to set:
# - POSTGRES_PASSWORD (change from default)
# - REDIS_PASSWORD (change from default)
# - LLM_MODEL (default: llama3.2:latest)
```

#### 3. Create Required Directories
```bash
mkdir -p models/whisper
mkdir -p models/piper
mkdir -p models/yolo
mkdir -p logs
mkdir -p sandbox
```

#### 4. Build Services
```bash
# Using Makefile (recommended)
make build

# OR using docker-compose directly
docker-compose build
```

**Build time:** 15-30 minutes (first time, with caching)

#### 5. Start Services
```bash
# Start all services
make up

# OR
docker-compose up -d
```

**Startup time:** 2-5 minutes (waiting for health checks)

#### 6. Verify Installation
```bash
# Check all containers are running
docker-compose ps

# Expected: All containers showing "Up" and "healthy"

# Check logs
make logs

# Test health endpoints
curl http://localhost:8000/health  # Orchestrator
curl http://localhost:8001/health  # STT
curl http://localhost:8002/health  # TTS
curl http://localhost:8003/health  # LLM
curl http://localhost:8004/health  # Vision
curl http://localhost:8006/health  # Executor
curl http://localhost:8007/health  # Bridge
```

#### 7. Access Dashboard
```bash
# Open in browser
http://localhost:3000

# Expected: Dashboard loads, shows service status
```

#### 8. Download AI Models (Optional)
```bash
# Download YOLOv8
bash scripts/download_models.sh

# Download Whisper model (manual)
# Visit: https://huggingface.co/ggerganov/whisper.cpp
# Place in: models/whisper/

# Download Piper voices (manual)
# Visit: https://github.com/rhasspy/piper/releases
# Place in: models/piper/

# Pull LLM model (automatic via Ollama)
docker-compose exec ollama ollama pull llama3.2:latest
```

---

## ‚öôÔ∏è Configuration

### Environment Variables

All configuration is in `.env` file:

```bash
# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=false

# LLM Configuration
LLM_MODEL=llama3.2:latest
LLM_ENDPOINT=http://ollama:11434
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2048

# Security
ENABLE_SANDBOX=true
DRY_RUN_MODE=false
MAX_CONCURRENT_ACTIONS=5
ACTION_TIMEOUT=30

# Database
DATABASE_URL=postgresql://jarvis:changeme@postgres:5432/jarvis_db
REDIS_URL=redis://:changeme@redis:6379/0

# Services URLs
STT_SERVICE_URL=http://stt_service:8001
TTS_SERVICE_URL=http://tts_service:8002
LLM_SERVICE_URL=http://llm_agent:8003
VISION_SERVICE_URL=http://vision_service:8004
MEMORY_SERVICE_URL=http://chromadb:8000
ACTION_EXECUTOR_URL=http://action_executor:8006

# MQTT (IoT)
MQTT_ENABLED=false
MQTT_BROKER=mosquitto
MQTT_PORT=1883

# Monitoring
ENABLE_METRICS=true
LOG_LEVEL=INFO
```

### Permissions Configuration

Edit `prompts/permissions.yml` to control what actions are allowed:

```yaml
actions:
  system:
    - open_app      # Open applications
    - search_web    # Web searches
    - screenshot    # Take screenshots
    - notification  # Send notifications
  
  dangerous:  # Require confirmation
    - delete_file
    - system_shutdown
    - execute_command

blacklist:
  - "rm -rf /"
  - "mkfs"
  - "dd if=/dev/zero"
```

---

## üß™ Testing

### Running Tests

```bash
# Run all tests
make test

# Run with coverage
make coverage

# Run specific test
pytest tests/test_orchestrator.py::test_name -v

# Run integration tests
pytest tests/ -m integration
```

### Manual Testing

#### Test STT Service
```bash
curl -X POST http://localhost:8001/test
```

#### Test TTS Service
```bash
curl -X POST http://localhost:8002/test
```

#### Test LLM Agent
```bash
curl -X POST http://localhost:8003/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Hello, who are you?"}'
```

#### Test Vision Service
```bash
# Upload test image
curl -X POST http://localhost:8004/detect \
  -F "image=@test_image.jpg"
```

---

## üîí Security

### Security Features

1. **Sandboxed Execution**
   - All system actions run in Docker containers
   - Resource limits enforced
   - No access to host filesystem

2. **Multi-Layer Validation**
   - Permission checks (YAML rules)
   - Input validation (Pydantic)
   - Safety assessment (AI-powered)
   - Blacklist enforcement

3. **Audit Logging**
   - All actions logged
   - User context recorded
   - Results tracked
   - Stored in PostgreSQL

4. **Dry-Run Mode**
   - Test actions without execution
   - Preview plan before running
   - Review potential impact

### Security Best Practices

‚úÖ Change default passwords in `.env`  
‚úÖ Keep sandbox enabled in production  
‚úÖ Review permissions regularly  
‚úÖ Monitor audit logs  
‚úÖ Update dependencies regularly  
‚úÖ Use HTTPS in production  
‚úÖ Enable firewall rules  

---

## üìä Monitoring & Logs

### Viewing Logs

```bash
# All services
make logs

# Specific service
docker-compose logs -f orchestrator
docker-compose logs -f stt_service

# Last 100 lines
docker-compose logs --tail=100 orchestrator
```

### Prometheus Metrics

```bash
# Access Prometheus UI
http://localhost:9090

# Metrics endpoint
http://localhost:8000/metrics
```

### Health Checks

```bash
# Aggregate health (via Bridge API)
curl http://localhost:8007/health

# Individual services
curl http://localhost:8000/health  # Orchestrator
curl http://localhost:8001/health  # STT
# ... etc
```

---

## üõ†Ô∏è Development

### Local Development Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# OR
venv\Scripts\activate  # Windows

# Install dependencies
cd apps/orchestrator_core
pip install -r requirements.txt
pip install -r requirements-dev.txt

# Install pre-commit hooks
pre-commit install

# Run linters
ruff check apps/ --fix
black apps/
mypy apps/ --ignore-missing-imports
```

### Code Quality Tools

- **Ruff** - Fast Python linter
- **Black** - Code formatter
- **MyPy** - Type checking
- **Pytest** - Testing framework

### Making Changes

1. Create feature branch
```bash
git checkout -b feature/your-feature
```

2. Make changes and test
```bash
# Run linters
make lint

# Run tests
make test

# Build locally
make build
```

3. Commit and push
```bash
git add .
git commit -m "feat: your feature description"
git push origin feature/your-feature
```

4. Create Pull Request on GitHub

---

## üö¢ Deployment

### Production Deployment

#### Option 1: Docker Compose (Single Server)

```bash
# On production server
git clone https://github.com/Youni-G5/AI-JARVIS.git
cd AI-JARVIS

# Configure production settings
cp .env.example .env
nano .env  # Set production values

# Build and start
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
```

#### Option 2: Kubernetes (Scalable)

```bash
# Deploy to Kubernetes
kubectl apply -f k8s/

# Scale services
kubectl scale deployment orchestrator --replicas=3
```

### Backup Strategy

```bash
# Backup PostgreSQL
docker-compose exec postgres pg_dump -U jarvis jarvis_db > backup.sql

# Backup ChromaDB
docker-compose exec chromadb tar -czf /backup/chroma.tar.gz /chroma/chroma

# Backup configuration
tar -czf config-backup.tar.gz .env prompts/
```

---

## üêõ Troubleshooting

### Common Issues

#### 1. Container won't start
```bash
# Check logs
docker-compose logs <service_name>

# Restart service
docker-compose restart <service_name>

# Rebuild if needed
docker-compose build --no-cache <service_name>
```

#### 2. Port already in use
```bash
# Find process
sudo lsof -i :8000

# Kill process
sudo kill -9 <PID>

# OR change port in docker-compose.yml
```

#### 3. Out of disk space
```bash
# Clean Docker resources
docker system prune -a --volumes

# Remove old images
docker image prune -a
```

#### 4. Slow performance
```bash
# Check resource usage
docker stats

# Increase Docker memory limit
# Docker Desktop > Settings > Resources > Memory

# Optimize services
# - Reduce concurrent actions
# - Lower LLM context window
# - Use smaller AI models
```

### Getting Help

1. **Documentation** - Check `docs/` folder
2. **GitHub Issues** - Search existing issues
3. **Logs** - Check service logs for errors
4. **Community** - Ask on GitHub Discussions

---

## üìà Performance Metrics

### Expected Performance

| Metric | Value |
|--------|-------|
| API Response Time | < 100ms |
| STT Latency | ~2-5s (streaming) |
| TTS Generation | ~1-3s |
| LLM Response | ~5-15s (depends on model) |
| Vision Analysis | ~1-3s |
| Action Execution | < 1s |
| Memory Retrieval | < 100ms |

### Resource Requirements

| Service | CPU | RAM | Disk |
|---------|-----|-----|------|
| Orchestrator | 0.5-1 core | 512MB | 100MB |
| STT Service | 1-2 cores | 2GB | 2GB |
| TTS Service | 0.5-1 core | 1GB | 1GB |
| LLM Agent | 2-4 cores | 8GB | 10GB |
| Vision Service | 1-2 cores | 2GB | 2GB |
| Action Executor | 0.5 core | 256MB | 100MB |
| PostgreSQL | 0.5 core | 512MB | 5GB |
| Redis | 0.5 core | 512MB | 1GB |
| ChromaDB | 0.5 core | 1GB | 5GB |
| **Total** | **8-12 cores** | **16-20GB** | **30-40GB** |

---

## üó∫Ô∏è Roadmap

### Version 1.0 (Current) ‚úÖ
- Core orchestration engine
- 7 microservices operational
- Basic frontend dashboard
- Security & sandboxing
- Documentation complete

### Version 1.1 (Q1 2026)
- [ ] Complete React dashboard
- [ ] Voice activation (wake word)
- [ ] Real-time video feed
- [ ] Mobile app (iOS/Android)

### Version 1.2 (Q2 2026)
- [ ] Multi-modal reasoning
- [ ] Context-aware conversations
- [ ] Proactive suggestions
- [ ] Custom model fine-tuning

### Version 2.0 (Q3 2026)
- [ ] Multi-user support
- [ ] Cloud sync (optional)
- [ ] Plugin system
- [ ] Marketplace

### Version 3.0 (Q4 2026)
- [ ] Enterprise features
- [ ] Team collaboration
- [ ] Advanced analytics
- [ ] Kubernetes native

---

## üìù Important Files to Know

### Must-Read Documentation
1. `README.md` - Project overview
2. `docs/Architecture.md` - System design
3. `docs/Installation.md` - Setup guide
4. `docs/CODE_AUDIT.md` - Code quality report
5. `docs/VERIFICATION_CHECKLIST.md` - Testing guide

### Key Configuration Files
1. `.env` - Environment variables
2. `docker-compose.yml` - Service orchestration
3. `prompts/permissions.yml` - Security rules
4. `pyproject.toml` - Python configuration

### Entry Points
1. `apps/orchestrator_core/main.py` - Main API
2. `frontend/pages/index.tsx` - Dashboard UI
3. `Makefile` - Build commands

---

## üí° Tips for New Developer

### First Week Checklist

**Day 1:**
- [ ] Read this document completely
- [ ] Clone repository
- [ ] Set up development environment
- [ ] Build and run services
- [ ] Access dashboard

**Day 2-3:**
- [ ] Read architecture docs
- [ ] Understand orchestrator flow
- [ ] Test each service individually
- [ ] Review API documentation

**Day 4-5:**
- [ ] Read code audit report
- [ ] Explore codebase
- [ ] Run tests
- [ ] Make small change and test

**Day 6-7:**
- [ ] Review security documentation
- [ ] Test error scenarios
- [ ] Read roadmap
- [ ] Plan first contribution

### Understanding the Flow

**Typical request flow:**
1. User speaks to microphone
2. Frontend captures audio
3. Audio sent to STT service ‚Üí text
4. Text sent to Orchestrator
5. Orchestrator asks LLM for plan
6. Plan validated by Safety Validator
7. Actions executed via Action Executor
8. Results stored in Memory
9. Response generated by LLM
10. Response synthesized by TTS
11. Audio played to user

### Code Navigation Tips

**To understand how X works:**
- Voice input ‚Üí `apps/stt_service/main.py`
- AI reasoning ‚Üí `apps/llm_agent/main.py`
- Action execution ‚Üí `apps/action_executor/executor.py`
- Security ‚Üí `apps/orchestrator_core/core/safety.py`
- Memory ‚Üí `apps/orchestrator_core/services/memory_client.py`

### Common Tasks

**Add a new action:**
1. Define in `prompts/permissions.yml`
2. Implement in `apps/action_executor/executor.py`
3. Test with dry-run mode
4. Document in API docs

**Add a new service:**
1. Create in `apps/new_service/`
2. Add Dockerfile
3. Add to `docker-compose.yml`
4. Create client in orchestrator
5. Update documentation

---

## üìû Contact & Support

### Repository
**GitHub:** https://github.com/Youni-G5/AI-JARVIS

### Documentation
**Docs Folder:** `docs/`  
**Wiki:** (TBD)

### Community
**Discussions:** GitHub Discussions  
**Issues:** GitHub Issues  

### Owner
**GitHub:** @Youni-G5  
**Email:** yassine.shopify3@gmail.com

---

## üéì Learning Resources

### Technologies Used

**Backend:**
- FastAPI: https://fastapi.tiangolo.com/
- asyncio: https://docs.python.org/3/library/asyncio.html
- Pydantic: https://docs.pydantic.dev/

**AI/ML:**
- Whisper: https://github.com/openai/whisper
- Ollama: https://ollama.ai/
- YOLOv8: https://docs.ultralytics.com/
- Piper TTS: https://github.com/rhasspy/piper

**Infrastructure:**
- Docker: https://docs.docker.com/
- Docker Compose: https://docs.docker.com/compose/
- PostgreSQL: https://www.postgresql.org/docs/
- Redis: https://redis.io/docs/

**Frontend:**
- Next.js: https://nextjs.org/docs
- React: https://react.dev/
- TailwindCSS: https://tailwindcss.com/

---

## ‚úÖ Pre-Handoff Checklist

### For Current Owner (Before Transfer)

- [x] Code pushed to GitHub
- [x] All documentation written
- [x] CI/CD configured
- [x] Tests passing
- [x] Security audit completed
- [x] Dependencies up-to-date
- [x] .env.example updated
- [x] README complete
- [x] This handoff doc created
- [ ] Secrets removed from repo
- [ ] Access credentials prepared
- [ ] Backup created

### For New Owner (After Transfer)

- [ ] Repository cloned
- [ ] Documentation read
- [ ] Development environment setup
- [ ] Services built and running
- [ ] Tests executed successfully
- [ ] Dashboard accessed
- [ ] API endpoints tested
- [ ] Logs reviewed
- [ ] Security settings verified
- [ ] Backup strategy implemented
- [ ] Questions asked/answered
- [ ] First contribution made

---

## üéØ Success Criteria

**You understand the project when you can:**

‚úÖ Explain the architecture to someone else  
‚úÖ Start all services without errors  
‚úÖ Add a new action and test it  
‚úÖ Troubleshoot common issues  
‚úÖ Make a code change confidently  
‚úÖ Understand the security model  
‚úÖ Navigate the codebase efficiently  

---

## üèÜ Final Notes

### Project Strengths

1. **Complete & Functional** - Not a prototype, ready to use
2. **Well-Architected** - Clean microservices design
3. **Secure** - Multi-layer security from day one
4. **Documented** - 15+ doc files, 10,000+ words
5. **Tested** - CI/CD, automated tests
6. **Scalable** - Microservices can scale independently
7. **Local-First** - Complete privacy, no cloud lock-in
8. **Open-Source** - MIT License, community-friendly

### Areas for Improvement

1. **Test Coverage** - Currently ~40%, target 80%+
2. **Frontend** - Basic dashboard, needs full implementation
3. **Performance** - LLM inference can be optimized
4. **Monitoring** - Prometheus setup, needs Grafana dashboards
5. **Documentation** - API docs need OpenAPI specs

### Vision Statement

> "AI-JARVIS aims to be the de facto open-source alternative to proprietary AI assistants, providing privacy, autonomy, and unlimited extensibility for individuals and organizations worldwide."

### Project Maturity

**Current Stage:** Beta (Production-Ready MVP)  
**Stability:** Stable for personal/small team use  
**Recommended For:** Developers, enthusiasts, researchers  
**Not Recommended For:** Large-scale production (yet)  

---

## üìÑ License & Legal

**License:** MIT  
**Copyright:** ¬© 2025 Youni-G5  
**Open-Source:** Yes, contributions welcome  

**Third-Party Components:**
- Whisper (MIT License)
- Ollama (MIT License)
- YOLOv8 (AGPL-3.0)
- Piper TTS (MIT License)
- FastAPI (MIT License)

---

**Document Version:** 1.0  
**Last Updated:** December 3, 2025  
**Author:** Youni-G5  
**Status:** Final for Handoff  

---

# üéâ Welcome to AI-JARVIS!

**This project represents 20+ commits, 100+ files, and a complete production-ready AI assistant platform.**

**Everything you need is documented. The code is clean. The architecture is solid.**

**Good luck, and happy building! üöÄ**